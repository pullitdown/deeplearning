{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \n",
    "    trans = [transforms.ToTensor()]#转换为tensor\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))#resize操作可选\n",
    "    trans = transforms.Compose(trans)#将转换操作聚合\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\",\n",
    "                                                    train=True,\n",
    "                                                    transform=trans,\n",
    "                                                    download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\",\n",
    "                                                   train=False,\n",
    "                                                   transform=trans,\n",
    "                                                   download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,num_workers=4),data.DataLoader(mnist_test, batch_size, shuffle=False,num_workers=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stepf\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train,test=load_data_fashion_mnist(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=train.__iter__().next()[0][0][0].numpy()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "im = Image.fromarray(np.uint8(img*255))\n",
    "im.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(block,self).__init__()\n",
    "        self.conv3=nn.Conv2d(16,16,3,padding=1)\n",
    "        self.Conv4=nn.Conv2d(16,24,3,padding=1)\n",
    "        self.Conv4=nn.Conv2d(24,16,3,padding=1)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        #使用super()方法调用基类的构造器，即nn.Module.__init__(self)\n",
    "        super(Net,self).__init__()\n",
    "        # 1 input image channel ,6 output channels,3*3 square convolution kernel\n",
    "        self.conv1=nn.Conv2d(1,6,3)#6,26,26\n",
    "        # 6 input channl,16 output channels,3*3 square convolution kernel\n",
    "        self.conv2=nn.Conv2d(6,16,3)#16,24,24\n",
    "        self.bn1=nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.conv3=nn.Conv2d(16,24,3)#24,10,10\n",
    "        self.conv4=nn.Conv2d(24,16,3)#16,8,8\n",
    "        self.bn2=nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # an affine operation:y=Wx+b\n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        self.Softmax=nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        # x是网络的输入，然后将x前向传播，最后得到输出\n",
    "        # 下面两句定义了两个2x2的池化层\n",
    "        x=self.conv1(x)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)#16,12,12\n",
    "        # if the size is square you can only specify a single number\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.conv3(x)\n",
    "        x=F.max_pool2d(F.relu(self.conv4(x)),2)#16,4,4\n",
    "        x=self.bn2(x)\n",
    "        x=self.relu(x)\n",
    "        x=x.view(-1,self.num_flat_features(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return self.Softmax(x)\n",
    "    def num_flat_features(self,x):\n",
    "        size=x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model=Net()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):#y_hat是预测的结果,y是已经编码的结果\n",
    "    if len(y_hat.shape)>1 and y_hat.shape[1]>1:\n",
    "        y_hat=y_hat.argmax(axis=1)\n",
    "    cmp=y_hat.type(y.dtype)==y\n",
    "    #print(\"y\",y,\" y_hat\",y_hat)\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def evaluate_accuracy(net,data_iter):\n",
    "    if isinstance(net,nn.Module):\n",
    "        net.eval()\n",
    "    a=Accumulator(2)\n",
    "    for X,y in data_iter:\n",
    "        a.add(accuracy(net(X),y),len(y))#tensor.numel()返回tensor的元素个数\n",
    "    return a[0]/a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator():\n",
    "    def __init__(self,num):\n",
    "        self.data=[0.0]*num\n",
    "    def __getitem__(self,ind):\n",
    "        return self.data[ind]\n",
    "    def add(self,*argv):\n",
    "        self.data=[a+float(b) for a,b in zip(self.data,argv)]\n",
    "    def clear(self):\n",
    "        self.data=[0.0]*len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ch3(net,train_iter,loss,updater):\n",
    "    if isinstance(net,nn.Module):\n",
    "        net.train()#将net的管理的参数梯度设为可改变\n",
    "    matric=Accumulator(3)\n",
    "    for X,y in tqdm(train_iter):#小批量迭代器\n",
    "        y_hat=net(X)\n",
    "\n",
    "        l=loss(y_hat,y)\n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "        #print(float(1)*l,accuracy(y_hat,y),len(y),y)\n",
    "        matric.add(float(1)*l,accuracy(y_hat,y),len(y))\n",
    "        \n",
    "    return matric[0]/matric[2],matric[1]/matric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        train_loss, train_acc = train_metrics\n",
    "        print(train_loss, train_acc,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15000 [00:00<?, ?it/s]C:\\Users\\stepf\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "C:\\Users\\stepf\\AppData\\Local\\Temp/ipykernel_24844/310693653.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.Softmax(x)\n",
      "100%|██████████| 15000/15000 [02:40<00:00, 93.50it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4258605686446031 0.7571666666666667 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:40<00:00, 93.69it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4145475690762202 0.8020833333333334 0.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:46<00:00, 90.11it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4126804085115592 0.8100166666666667 0.8114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:49<00:00, 88.50it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41108029570976895 0.8165333333333333 0.7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:52<00:00, 86.75it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4102311465183894 0.8200666666666667 0.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:57<00:00, 84.44it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40934780556758243 0.8235 0.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:55<00:00, 85.48it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4087286825497945 0.8259666666666666 0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:54<00:00, 86.19it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4109242945412795 0.8173166666666667 0.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:54<00:00, 86.06it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41230358608762424 0.8116833333333333 0.8075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:55<00:00, 85.38it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105645790060361 0.8187833333333333 0.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:58<00:00, 84.09it/s]\n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41282045432726544 0.8098166666666666 0.7934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:57<00:00, 84.37it/s]\n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40879009139736494 0.8258666666666666 0.8191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:46<00:00, 89.86it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.410062446641922 0.8208833333333333 0.8198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [03:10<00:00, 78.77it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4111217921177546 0.8167333333333333 0.8035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:58<00:00, 84.25it/s] \n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41012115316589676 0.8205833333333333 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [03:13<00:00, 77.32it/s]\n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4130786600748698 0.8087333333333333 0.8191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [03:22<00:00, 73.93it/s]\n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40861382756431897 0.82655 0.8323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [03:04<00:00, 81.50it/s]\n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4116420346458753 0.8145333333333333 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [03:18<00:00, 75.54it/s]\n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4089118312438329 0.8254666666666667 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [03:23<00:00, 73.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.409984196271499 0.8211833333333334 0.8066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ch3(model,train,test,loss,20,optimizer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2651b5ef9a76fc3c7c68d712767f3ccc4f9b14ef7b49dbecd7e6bff4f9a25078"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
